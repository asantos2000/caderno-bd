## Classificação de tipos faciais

Os dados do arquivo tipofacial (disponível [aqui](http://www.ime.usp.br/~jmsinger/MorettinSinger/tipofacial.xls)) foram extraídos de um estudo odontológico realizado pelo Dr. Flávio Cotrim Vellini. Um dos objetivos era utilizar medidas entre diferentes pontos do crânio para caracterizar indivíduos com diferentes tipos faciais, a saber, braquicéfalos, mesocéfalos e dolicocéfalos (grupos). O conjunto de dados contém observações de 11 variáveis em 101 pacientes. Para efeitos didáticos, considere apenas a altura facial (altfac) e a profundidade facial (proffac) como variáveis preditoras.

### Pacotes

Pacotes necessários para estes exercícios:

```{r warning=FALSE, echo=FALSE}
library(readxl)
library(tidyverse)
library(readxl)
library(ggthemes)
library(plotly)
library(knitr)
library(kableExtra)
library(rpart)
library(rpart.plot)
library(caret)
library(MASS)
library(httr)
library(readxl)
library(tibble)
library(e1071)
library(neuralnet)
library(factoextra)
library(ggpubr)
library(nnet)
```

### Conjunto de dados

```{r}
httr::GET("http://www.ime.usp.br/~jmsinger/MorettinSinger/tipofacial.xls", httr::write_disk("../dados/tipofacial.xls", overwrite = TRUE))

tipofacial <- read_excel("../dados/tipofacial.xls")
str(tipofacial)
```

Número de observações `r nrow(tipofacial)`.

#### Categorizando a variável de grupo.

```{r}
# Considerar (altfac) e a profundidade facial (proffac) como variáveis preditoras.

tipofacial$sumfac = tipofacial$altfac + tipofacial$proffac
tipofacial$grupo = as.factor(tipofacial$grupo)
```

```{r}
plot(tipofacial$sumfac  ~ tipofacial$grupo)
print(tipofacial, n = 32)
```

```{r}
summary(tipofacial)
sd(tipofacial$sumfac)
```

Criando um dataframe para comparar as métricas dos modelos.

```{r}
model_eval <- data.frame(matrix(ncol = 9, nrow = 0))

colnames(model_eval) <- c('Model', 'Algorithm', 'Accuracy', 'Sensitivity_C1', 'Sensitivity_C2', 'Sensitivity_C3', 'Specificity_C1', 'Specificity_C2', 'Specificity_C3')
```


### Generalized Linear Models

```{r}
glm.fit = multinom(grupo ~ sumfac, data=tipofacial)
summary(glm.fit)
```

```{r}
predito = predict(glm.fit, newdata = tipofacial)
cm = confusionMatrix(predito, tipofacial$grupo)
cm

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("glm.fit", "glm", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])

```


Seprando dados de treinamento (70%) e testes (30%).


```{r}

alpha=0.7
d = sort(sample(nrow(tipofacial), nrow(tipofacial)*alpha))
train = tipofacial[d,]
test = tipofacial[-d,]

glm.fit = multinom(grupo ~ sumfac, data=train)

summary(glm.fit)

predito = predict(glm.fit, newdata = test)
cm = confusionMatrix(predito, test$grupo)
cm

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("glm.fit-split", "glm", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```

```{r}
kable(model_eval) %>%
  kable_styling(latex_options = "striped")
```


Treinar o modelo com um conjunto de dados diferente do de teste mostrou que o modelo tem uma capcidade razoável de generalização.

### Linear Discriminant Analysis - Fisher

```{r}
modFisher01 = lda(grupo ~ sumfac, data = tipofacial)
predito = predict(modFisher01)
classPred = predito$class
cm = confusionMatrix(classPred, tipofacial$grupo)
cm

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("modFisher01", "lda", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```

### Bayes

```{r}
modBayes01 = lda(grupo ~ sumfac, data = tipofacial, prior = c(0.25, 0.50, 0.25))
predito = predict(modBayes01)
classPred = predito$class
cm = confusionMatrix(classPred, tipofacial$grupo)
cm

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("modBayes01-prior 0.25 / 0.50 / 0.25", "lda", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```

Naive Bayes

```{r}
modNaiveBayes01 = naiveBayes(grupo ~ sumfac, data = tipofacial)
predito = predict(modNaiveBayes01, tipofacial)
cm = confusionMatrix(predito, tipofacial$grupo)
cm

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("modNaiveBayes01", "naiveBayes", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```

### Decison tree

```{r}
modArvDec01 = rpart(grupo ~ sumfac, data = tipofacial) 
prp(modArvDec01,  faclen=0, #use full names for factor labels
    extra=1, #display number of observations for each terminal node
    roundint=F, #don't round to integers in output
    digits=5)

predito = predict(modArvDec01, type = "class")
cm = confusionMatrix(predito, tipofacial$grupo)
cm

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("modArvDec01", "rpart", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```

```{r}
x = 1:nrow(tipofacial)
plot(tipofacial$sumfac ~ x, col = tipofacial$grupo)
```

### SVM

```{r}
modSVM01 = svm(grupo ~ sumfac, data = tipofacial, kernel = "linear")
predito = predict(modSVM01, type = "class")
cm = confusionMatrix(predito, tipofacial$grupo)

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("modSVM01", "svm", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```

### neuralnet

```{r}
modRedNeural01 = neuralnet(grupo ~ sumfac, data = tipofacial, hidden = c(2,4,3))
plot(modRedNeural01)

ypred = neuralnet::compute(modRedNeural01, tipofacial)
yhat = ypred$net.result

yhat = round(yhat)

yhat=data.frame("yhat"= dplyr::case_when(yhat[ ,1:1]==1 ~ "braq", 
                                         yhat[ ,2:2]==1 ~ "dolico",
                                         TRUE ~ "meso"))

cm = confusionMatrix(tipofacial$grupo, as.factor(yhat$yhat))
cm

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("modRedNeural01", "neuralnet", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```

### KNN

```{r}
modKnn1_01 = knn3(grupo ~ sumfac, data = tipofacial, k = 1)
predito = predict(modKnn1_01, tipofacial, type = "class")
cm = confusionMatrix(predito, tipofacial$grupo)
cm

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("modKnn1_01-k=1", "knn3", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```

k = 3

```{r}
modKnn3_01 = knn3(grupo ~ sumfac, data = tipofacial, k = 3)
predito = predict(modKnn3_01, tipofacial, type = "class")
cm = confusionMatrix(predito, tipofacial$grupo, positive = "0")

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("modKnn3_01-k=3", "knn3", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```

k = 5

```{r}
modKnn5_01 = knn3(grupo ~ sumfac, data = tipofacial, k = 5)
predito = predict(modKnn5_01, tipofacial, type = "class")
cm = confusionMatrix(predito, tipofacial$grupo, positive = "0")
cm

# Adiciona as métricas no df
model_eval[nrow(model_eval) + 1,] <- c("modKnn3_01-k=5", "knn3", cm$overall['Accuracy'], cm$byClass[,1], cm$byClass[,2])
```
### Avaliando os modelos

```{r echo=FALSE}
kable(model_eval) %>%
  kable_styling(latex_options = "striped")
```

Todos os modelos tiveram uma performace bem semelhante, sendo que knn, com $k=3$, obteve o melhor resultado em todas as medidas.

### Agrupamento

```{r}
tipofacialS = subset(tipofacial, select=c("sexo", "idade", "altfac", "proffac"))

dummy <- dummyVars(" ~ .", data=tipofacialS)
newdata <- data.frame(predict(dummy, newdata = tipofacialS)) 

d <- dist(newdata, method = "maximum")
grup = hclust(d, method = "ward.D")
plot(grup, cex = 0.6)

groups <- cutree(grup, k=3)
table(groups, tipofacial$grupo)
```



```{r}
km1 = kmeans(newdata, 4)
p1 = fviz_cluster(km1, data=newdata,
                  palette = c("#2E9FDF", "#FC4E07", "#E7B800", "#E7B700"),
                  star.plot=FALSE,
                  # repel=TRUE,
                  ggtheme=theme_bw())
p1
```

```{r}
groups = km1$cluster
table(groups, tipofacial$grupo)
```
